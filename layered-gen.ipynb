{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "581b91d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import (\n",
    "    StableDiffusionXLControlNetPipeline,\n",
    "    ControlNetModel,\n",
    "    StableDiffusionXLInpaintPipeline,\n",
    "    AutoencoderKL\n",
    ")\n",
    "from diffusers.utils import load_image, make_image_grid\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "device = \"cuda\"\n",
    "torch_dtype = torch.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a47c5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e19e0e967e84ff39a8f521b35c174f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "controlnet = ControlNetModel.from_pretrained(\n",
    "    \"diffusers/controlnet-canny-sdxl-1.0\",\n",
    "    torch_dtype=torch_dtype\n",
    ")\n",
    "\n",
    "text2img_pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    controlnet=controlnet,\n",
    "    torch_dtype=torch_dtype\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b067d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea860c9c29aa4d1fa83c0c58d6f4592c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The config attributes {'decay': 0.9999, 'inv_gamma': 1.0, 'min_decay': 0.0, 'optimization_step': 37000, 'power': 0.6666666666666666, 'update_after_step': 0, 'use_ema_warmup': False} were passed to UNet2DConditionModel, but are not expected and will be ignored. Please verify your config.json configuration file.\n"
     ]
    }
   ],
   "source": [
    "inpaint_pipe = StableDiffusionXLInpaintPipeline.from_pretrained(\n",
    "    \"diffusers/stable-diffusion-xl-1.0-inpainting-0.1\",\n",
    "    torch_dtype=torch.float16\n",
    ").to(device)\n",
    "\n",
    "inpaint_pipe.enable_xformers_memory_efficient_attention()\n",
    "inpaint_pipe.enable_model_cpu_offload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "def canny_from_image(image: Image.Image, low=100, high=200):\n",
    "    image = image.resize((1024, 1024))\n",
    "    image_np = np.array(image.convert(\"RGB\"))\n",
    "    edges = cv2.Canny(image_np, low, high)\n",
    "    edges_rgb = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)\n",
    "    return Image.fromarray(edges_rgb)\n",
    "\n",
    "# === 5. Generate Initial Background Layer ===\n",
    "def generate_background(prompt: str):\n",
    "    blank = Image.new(\"RGB\", (1024, 1024), (255, 255, 255))\n",
    "    canny = canny_from_image(blank)  # Uniform background → edges are blank\n",
    "    result = text2img_pipe(\n",
    "        prompt=prompt,\n",
    "        image=canny,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7.5\n",
    "    ).images[0]\n",
    "    return result\n",
    "\n",
    "# === 6. Inpaint Over Existing Image ===\n",
    "def inpaint_layer(prompt: str, base_image: Image.Image, mask: Image.Image):\n",
    "    base_image = base_image.resize((1024, 1024))\n",
    "    mask = mask.resize((1024, 1024)).convert(\"L\")\n",
    "\n",
    "    result = inpaint_pipe(\n",
    "        prompt=prompt,\n",
    "        image=base_image,\n",
    "        mask_image=mask,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=8.5\n",
    "    ).images[0]\n",
    "\n",
    "    return result\n",
    "\n",
    "# === 7. Create Circular Mask ===\n",
    "def circular_mask(center, radius, size=(1024, 1024)):\n",
    "    mask = Image.new(\"L\", size, 0)\n",
    "    draw = ImageDraw.Draw(mask)\n",
    "    x, y = center\n",
    "    draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=255)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a5c2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8. Pipeline: Blank → Background → Foreground ===\n",
    "def layered_generation():\n",
    "    # Layer 1: Background\n",
    "    bg_prompt = \"a peaceful mountain landscape with a lake, in golden hour lighting\"\n",
    "    background = generate_background(bg_prompt)\n",
    "    background.save(\"layer1_background.png\")\n",
    "\n",
    "    # Layer 2: Midground Object (e.g., cabin)\n",
    "    cabin_center = (512, 650)\n",
    "    cabin_radius = 300\n",
    "    cabin_mask = circular_mask(center=cabin_center, radius=cabin_radius)\n",
    "    cabin_mask.save(\"debug_cabin_mask.png\")\n",
    "    cabin_prompt = (\n",
    "        \"a cozy wooden log cabin with a triangular roof, warm lights glowing from the windows, \"\n",
    "        \"located in the center of the image, clearly visible, surrounded by trees, chimney with smoke, photorealistic\"\n",
    "    )\n",
    "    midground = inpaint_layer(cabin_prompt, background, cabin_mask)\n",
    "    midground.save(\"layer2_cabin.png\")\n",
    "\n",
    "    # Layer 3: Foreground Subject (e.g., person)\n",
    "    # Automatically place person mask just below the cabin\n",
    "    person_center = (cabin_center[0], cabin_center[1] + int(cabin_radius * 0.5))\n",
    "    person_radius = int(cabin_radius * 0.6)\n",
    "    person_mask = circular_mask(center=person_center, radius=person_radius)\n",
    "    person_mask.save(\"debug_person_mask.png\")\n",
    "    person_prompt = (\n",
    "        \"a hiker wearing a red jacket, standing in front of the cabin near the lake, full body, clearly visible\"\n",
    "    )\n",
    "    final_image = inpaint_layer(person_prompt, midground, person_mask)\n",
    "    final_image.save(\"layer3_person.png\")\n",
    "\n",
    "    print(\"✅ Image generated in 3 layers and saved.\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b18c7e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636d4748bd3f4e458c7dbf9a3ab4d707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Image generated in 3 layers and saved.\n"
     ]
    }
   ],
   "source": [
    "layered_generation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480b2bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SLAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
